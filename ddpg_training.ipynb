{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Actions: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O| | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O| | | | \n",
      "  ----------\n",
      "  X| | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[2. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O|O| | | \n",
      "  ----------\n",
      "  X| | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[1. 1. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O|O| | | \n",
      "  ----------\n",
      "  X|X| | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[2. 2. 2. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O|O|O| | \n",
      "  ----------\n",
      "  X|X| | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[1. 1. 1. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O|O|O| | \n",
      "  ----------\n",
      "  X|X|X| | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[2. 2. 2. 2. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O|O|O|O| \n",
      "  ----------\n",
      "  X|X|X| | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[1. 1. 1. 1. 0. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 0 False\n",
      "  O|O|O|O| \n",
      "  ----------\n",
      "  X|X|X|X| \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "False 0\n",
      "[2. 2. 2. 2. 2. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] 1 True\n",
      "  O|O|O|O|O\n",
      "  ----------\n",
      "  X|X|X|X| \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "  ----------\n",
      "   | | | | \n",
      "True 1\n",
      "Game Over!\n",
      "Available Actions: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frozenwolf/miniconda3/lib/python3.10/site-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
     ]
    }
   ],
   "source": [
    "from gym_tictactoe.env import TicTacToeEnv\n",
    "import numpy as np\n",
    "\n",
    "env = TicTacToeEnv(size=5)\n",
    "\n",
    "print(\"Available Actions:\", env.available_actions())\n",
    "\n",
    "actions = [0, 5, 1, 6, 2, 7, 3, 8, 4, 9]\n",
    "for action in actions:\n",
    "    observation, reward, done, trunc, _ = env.step(np.float32(action))\n",
    "    print(observation, reward, done)\n",
    "    env.render()\n",
    "    print(done, reward)\n",
    "    if done or trunc:\n",
    "        print(\"Game Over!\")\n",
    "        break\n",
    "\n",
    "print(\"Available Actions:\", env.available_actions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to logs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4d2c19d17041948815b1307379b21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/frozenwolf/miniconda3/lib/python3.10/site-packages/gymnasium/spaces/box.py:240: UserWarning: <span style=\"color: #808000; text-decoration-color: #808000\">WARN: Casting </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">input x to numpy array.</span>\n",
       "  gym.logger.warn(\"Casting input x to numpy array.\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/frozenwolf/miniconda3/lib/python3.10/site-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting \u001b[0m\n",
       "\u001b[33minput x to numpy array.\u001b[0m\n",
       "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.7      |\n",
      "|    ep_rew_mean     | 0.6      |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 973      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 77       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.8      |\n",
      "|    ep_rew_mean     | 0.45     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 156      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.167   |\n",
      "|    critic_loss     | 0.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 56       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.93     |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 238      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.247   |\n",
      "|    critic_loss     | 0.0136   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 136      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.75     |\n",
      "|    ep_rew_mean     | 0.45     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 75       |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 310      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.295   |\n",
      "|    critic_loss     | 0.00619  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 207      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.72     |\n",
      "|    ep_rew_mean     | 0.44     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 69       |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 386      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.384   |\n",
      "|    critic_loss     | 0.011    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 283      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.67     |\n",
      "|    ep_rew_mean     | 0.467    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 64       |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 460      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.392   |\n",
      "|    critic_loss     | 0.0123   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 358      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.57     |\n",
      "|    ep_rew_mean     | 0.486    |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 530      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.452   |\n",
      "|    critic_loss     | 0.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 428      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.55     |\n",
      "|    ep_rew_mean     | 0.487    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 604      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.489   |\n",
      "|    critic_loss     | 0.0125   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 501      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.57     |\n",
      "|    ep_rew_mean     | 0.389    |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 681      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.513   |\n",
      "|    critic_loss     | 0.0182   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 579      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.5      |\n",
      "|    ep_rew_mean     | 0.34     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 750      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.536   |\n",
      "|    critic_loss     | 0.033    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 649      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.47     |\n",
      "|    ep_rew_mean     | 0.33     |\n",
      "| time/              |          |\n",
      "|    episodes        | 110      |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 824      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.553   |\n",
      "|    critic_loss     | 0.0161   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 721      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.5      |\n",
      "|    ep_rew_mean     | 0.33     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 60       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 906      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.601   |\n",
      "|    critic_loss     | 0.0221   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 803      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.5      |\n",
      "|    ep_rew_mean     | 0.34     |\n",
      "| time/              |          |\n",
      "|    episodes        | 130      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 988      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.647   |\n",
      "|    critic_loss     | 0.0166   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 885      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.56     |\n",
      "|    ep_rew_mean     | 0.31     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 1066     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.69    |\n",
      "|    critic_loss     | 0.0136   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 963      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.6      |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    episodes        | 150      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 1146     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.71    |\n",
      "|    critic_loss     | 0.012    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1046     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.64     |\n",
      "|    ep_rew_mean     | 0.31     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 1224     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.729   |\n",
      "|    critic_loss     | 0.0153   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1121     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.73     |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    episodes        | 170      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 1303     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.773   |\n",
      "|    critic_loss     | 0.0189   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1200     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.78     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 1382     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.786   |\n",
      "|    critic_loss     | 0.0151   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1280     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.77     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    episodes        | 190      |\n",
      "|    fps             | 59       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 1458     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.778   |\n",
      "|    critic_loss     | 0.0257   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1355     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m new_logger \u001b[39m=\u001b[39m configure(tmp_path, [\u001b[39m\"\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m model\u001b[39m.\u001b[39mset_logger(new_logger)\n\u001b[0;32m---> 28\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m20000\u001b[39;49m, log_interval\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,)\n\u001b[1;32m     29\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpgmodel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m vec_env \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_env()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m: SelfDDPG,\n\u001b[1;32m    116\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfDDPG:\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    124\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    125\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    126\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    127\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    128\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    129\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    130\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[39mself\u001b[39m: SelfTD3,\n\u001b[1;32m    215\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfTD3:\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    223\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    224\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    225\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    226\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    227\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    228\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    229\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_freq, TrainFreq)  \u001b[39m# check done in _setup_learn()\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 328\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    329\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    330\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    331\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    332\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    333\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    334\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    335\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    336\u001b[0m     )\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training:\n\u001b[1;32m    339\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    557\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    559\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    563\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m terminated \u001b[39mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/Desktop/AIML-Project/gym_tictactoe/env.py:161\u001b[0m, in \u001b[0;36mTicTacToeEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    158\u001b[0m cpyboard[cpyboard\u001b[39m==\u001b[39m\u001b[39m4\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    160\u001b[0m \u001b[39m# print(\"=\",cpyboard)\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m zero_locs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhere(cpyboard)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    162\u001b[0m \u001b[39m# print(zero_locs)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# print(\"========\",zero_locs)\u001b[39;00m\n\u001b[1;32m    164\u001b[0m distances \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(zero_locs \u001b[39m-\u001b[39m action)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/numpy/core/multiarray.py:346\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m    inner(a, b, /)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m (a, b)\n\u001b[0;32m--> 346\u001b[0m \u001b[39m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[39m.\u001b[39mwhere)\n\u001b[1;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhere\u001b[39m(condition, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    348\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[39m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import DQN, DDPG, PPO\n",
    "from gym_tictactoe.env import TicTacToeEnv\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from gym_tictactoe.env import TicTacToeEnv\n",
    "import numpy as np\n",
    "\n",
    "# env = TicTacToeEnv(size=5)\n",
    "import numpy as np\n",
    "tmp_path = \"logs/\"\n",
    "# set up logger\n",
    "\n",
    "env = TicTacToeEnv()\n",
    "eval_callback = EvalCallback(env, best_model_save_path=\"ddpgmodel/\",\n",
    "                             log_path=\"logs/\", eval_freq=1000,\n",
    "                             deterministic=True, render=False, n_eval_episodes=10)\n",
    "# n_actions = env.action_space.shape[-1]\n",
    "\n",
    "action_noise = np.asarray(1)\n",
    "action_noise = NormalActionNoise(mean=np.zeros(1), sigma=action_noise)\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, verbose=1,  batch_size=200, action_noise=action_noise)\n",
    "new_logger = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "model.set_logger(new_logger)\n",
    "model.learn(total_timesteps=20000, log_interval=10, progress_bar=True,)\n",
    "model.save(\"ddpgmodel\")\n",
    "\n",
    "vec_env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpgmodel/best_model.zip\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "\n",
    "done = False\n",
    "obs, info = env.reset()\n",
    "observation = obs\n",
    "while not done:\n",
    "    action, _states = model.predict(observation, deterministic=True)\n",
    "    observation, reward, done, trunc, _ = env.step(action)\n",
    "    print(observation, reward, done)\n",
    "    env.render()\n",
    "\n",
    "    if done or trunc:\n",
    "        print(\"Game Over!\")\n",
    "        break\n",
    "\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs, deterministic=True)\n",
    "#     obs, reward, terminated, truncated, info = env.step(action)\n",
    "#     if terminated or truncated:\n",
    "#         obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 8.0, (), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False False\n",
      "   |O| \n",
      "  ------\n",
      "   | | \n",
      "  ------\n",
      "   | | \n",
      "[0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 False False\n",
      "   |O| \n",
      "  ------\n",
      "   | | \n",
      "  ------\n",
      "   | |X\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 2.]\n",
      "0 False False\n",
      "   |O| \n",
      "  ------\n",
      "  O| | \n",
      "  ------\n",
      "   | |X\n",
      "[0. 2. 0. 2. 0. 0. 0. 0. 1.]\n",
      "0 False False\n",
      "  X|O| \n",
      "  ------\n",
      "  O| | \n",
      "  ------\n",
      "   | |X\n",
      "[2. 1. 0. 1. 0. 0. 0. 0. 2.]\n",
      "0 False False\n",
      "  X|O| \n",
      "  ------\n",
      "  O|O| \n",
      "  ------\n",
      "   | |X\n",
      "[1. 2. 0. 2. 2. 0. 0. 0. 1.]\n",
      "0 False False\n",
      "  X|O| \n",
      "  ------\n",
      "  O|O| \n",
      "  ------\n",
      "   |X|X\n",
      "[2. 1. 0. 1. 1. 0. 0. 2. 2.]\n",
      "0 False False\n",
      "  X|O| \n",
      "  ------\n",
      "  O|O| \n",
      "  ------\n",
      "  O|X|X\n",
      "[1. 2. 0. 2. 2. 0. 2. 1. 1.]\n",
      "0 False False\n",
      "  X|O|X\n",
      "  ------\n",
      "  O|O| \n",
      "  ------\n",
      "  O|X|X\n",
      "[2. 1. 2. 1. 1. 0. 1. 2. 2.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(observation)\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m altter:\n\u001b[0;32m---> 13\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mEnter action: \u001b[39;49m\u001b[39m\"\u001b[39;49m)))\n\u001b[1;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(observation, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = DDPG.load(\"ddpgmodel/best_model.zip\")\n",
    "\n",
    "\n",
    "done = False\n",
    "obs, info = env.reset()\n",
    "\n",
    "altter = True\n",
    "observation = obs\n",
    "while not done:\n",
    "    print(observation)\n",
    "    if altter:\n",
    "        action = np.asarray(int(input(\"Enter action: \")))\n",
    "        \n",
    "    else:\n",
    "        action, _states = model.predict(observation, deterministic=True)\n",
    "    observation, reward, done, trunc, _ = env.step(action)\n",
    "    altter = not altter\n",
    "    # print(observation, reward, done)\n",
    "    print(reward, done, trunc)\n",
    "    env.render()\n",
    "\n",
    "    if done or trunc:\n",
    "        print(\"Game Over!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
