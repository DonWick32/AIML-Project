train/learning_rate,time/episodes,time/total_timesteps,time/time_elapsed,train/n_updates,rollout/ep_len_mean,train/actor_loss,train/critic_loss,rollout/ep_rew_mean,time/fps,eval/mean_ep_length,eval/mean_reward
0.001,10,139,0,29,13.9,-0.053047000573804744,0.02500840426924137,0.3,882,,
0.001,20,269,0,159,13.45,-0.1191730539386089,0.00016576419651615791,0.65,364,,
0.001,30,413,1,300,13.766666666666667,-0.1648469278588891,0.0017150387066067196,0.6333333333333333,316,,
0.001,,500,,396,,-0.16768420208245516,0.00010308463106412091,,,16.0,0.0
0.001,40,578,2,467,14.45,-0.18254578113555908,0.0017212323764397297,0.45,279,,
0.001,50,734,2,621,14.68,-0.2127342956761519,0.0044187422899995,0.34,273,,
0.001,60,875,3,766,14.583333333333334,-0.21763465274125338,0.0022315403184620664,0.2,268,,
0.001,,1000,,895,,-0.2326739775016904,0.0016387485520681366,,,16.0,0.0
0.001,70,1030,3,919,14.714285714285714,-0.2224531788378954,0.0018242677057666394,0.17142857142857143,261,,
0.001,80,1172,4,1062,14.65,-0.219772822327084,0.0024012752756890324,0.15,259,,
0.001,90,1322,5,1214,14.688888888888888,-0.23799005548159283,0.004257722245529294,0.14444444444444443,258,,
0.001,100,1473,5,1360,14.73,-0.2541852965950966,0.0027326834097038954,0.13,258,,
0.001,,1500,,1392,,-0.26081924699246883,0.0028606132400454953,,,16.0,-1.0
0.001,110,1640,6,1527,15.01,-0.26264681986400057,0.004498412283802671,0.08,254,,
0.001,120,1796,7,1683,15.27,-0.2920313626527786,0.008212219210690819,-0.04,254,,
0.001,130,1944,7,1831,15.31,-0.317159716039896,0.0076855629837761326,-0.1,253,,
0.001,,2000,,1895,,-0.29325537383556366,0.007951222767587751,,,16.0,-1.0
